# -*- coding: utf-8 -*-
"""MeuProjetoCliniCase.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tl5KlTG54H1wyEYtbmObrPKZ-gt2S_5F
"""

# Importação das Bibliotecas necessárias
!pip install scikit-learn --upgrade
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import xgboost as xgb
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import (accuracy_score, balanced_accuracy_score, precision_score,
                             recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay)
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.ensemble import RandomForestClassifier

# Carregando o dataset
df = pd.read_excel('CliniData(2).xlsx')

# Convertendo colunas float para int e reduzindo o uso de memória
df['Avaliação'] = df['Avaliação'].astype('int8')

# Configuração do estilo do seaborn
sns.set(style="whitegrid")

# Definindo variáveis X e Y para o modelo
X = df.drop(columns=["UserID", "Churn", "Data Cadastro"], axis=1)
y = df["Churn"]

# Aplicando LabelEncoder para a variável target "Churned"
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Aplicando one-hot encoding nas variáveis categóricas de X
X = pd.get_dummies(X)

# Dividindo os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, stratify=y_encoded)

# Aplicando MinMaxScaler após a divisão dos dados
mm = MinMaxScaler()
X_train = pd.DataFrame(mm.fit_transform(X_train), columns=X.columns)
X_test = pd.DataFrame(mm.transform(X_test), columns=X.columns)

# Modelo de Regressão Logística
model = LogisticRegression()
lr = model.fit(X_train, y_train)

# Previsões no conjunto de teste
y_pred_lr = lr.predict(X_test)

# Matriz de Confusão
cm = confusion_matrix(y_test, y_pred_lr)
ConfusionMatrixDisplay(confusion_matrix=cm).plot(values_format='d')
plt.show()

# Avaliação de métricas para o modelo de Regressão Logística
metrics = {'accuracy': accuracy_score, 'balanced_accuracy': balanced_accuracy_score,
           'precision': precision_score, 'recall': recall_score, 'f1': f1_score, 'roc_auc': roc_auc_score}

for name, metric in metrics.items():
    if name == 'roc_auc':
        print(f"ROCAUC (Treino): {metric(y_train, lr.predict_proba(X_train)[:, 1])}")
        print(f"ROCAUC (Teste): {metric(y_test, lr.predict_proba(X_test)[:, 1])}")
    else:
        print(f"{name.capitalize()} (Treino): {metric(y_train, lr.predict(X_train))}")
        print(f"{name.capitalize()} (Teste): {metric(y_test, y_pred_lr)}")
    print("====================================")

# Modelo Random Forest
rf = RandomForestClassifier()
rf.fit(X_train, y_train)

# Previsões com Random Forest
y_pred_rf = rf.predict(X_test)

# Matriz de Confusão
cm_rf = confusion_matrix(y_test, y_pred_rf)
ConfusionMatrixDisplay(confusion_matrix=cm_rf).plot(values_format='d')
plt.show()

# Avaliação de métricas para o modelo Random Forest
for name, metric in metrics.items():
    if name == 'roc_auc':
        print(f"ROCAUC (Treino): {metric(y_train, rf.predict_proba(X_train)[:, 1])}")
        print(f"ROCAUC (Teste): {metric(y_test, rf.predict_proba(X_test)[:, 1])}")
    else:
        print(f"{name.capitalize()} (Treino): {metric(y_train, rf.predict(X_train))}")
        print(f"{name.capitalize()} (Teste): {metric(y_test, y_pred_rf)}")
    print("====================================")

# GridSearchCV para Random Forest
parameters = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
              'n_estimators': [100, 300, 500]}

grid_search = GridSearchCV(rf, parameters, scoring='accuracy', cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Aplicando o melhor modelo encontrado pelo GridSearch
best_params = grid_search.best_estimator_.get_params()
rf_tuned = RandomForestClassifier(**best_params)
rf_tuned.fit(X_train, y_train)

# Previsões com o modelo ajustado
y_pred_rf_tuned = rf_tuned.predict(X_test)

# Matriz de Confusão do modelo ajustado
cm_rf_tuned = confusion_matrix(y_test, y_pred_rf_tuned)
ConfusionMatrixDisplay(confusion_matrix=cm_rf_tuned).plot(values_format='d')
plt.show()

# Avaliação de métricas para o modelo Random Forest ajustado
for name, metric in metrics.items():
    if name == 'roc_auc':
        print(f"ROCAUC (Treino): {metric(y_train, rf_tuned.predict_proba(X_train)[:, 1])}")
        print(f"ROCAUC (Teste): {metric(y_test, rf_tuned.predict_proba(X_test)[:, 1])}")
    else:
        print(f"{name.capitalize()} (Treino): {metric(y_train, rf_tuned.predict(X_train))}")
        print(f"{name.capitalize()} (Teste): {metric(y_test, y_pred_rf_tuned)}")
    print("====================================")

# Treinando o modelo XGBoost
xgb_model = xgb.XGBClassifier(scale_pos_weight=(len(y_train) - sum(y_train)) / sum(y_train),  # Ajuste para classes desbalanceadas
                              max_depth=3,
                              learning_rate=0.1,
                              n_estimators=50,
                              objective='binary:logistic',
                              random_state=42,
                              use_label_encoder=False)

xgb_model.fit(X_train, y_train)

# Avaliação no conjunto de treino
y_train_pred = xgb_model.predict(X_train)
y_train_proba = xgb_model.predict_proba(X_train)[:, 1]

# Avaliação no conjunto de teste
y_test_pred = xgb_model.predict(X_test)
y_test_proba = xgb_model.predict_proba(X_test)[:, 1]

# Função de Avaliação para Métricas Detalhadas
def evaluate_model(y_true, y_pred, y_proba, dataset_name):
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred),
        'balanced_accuracy': balanced_accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred, zero_division=0),
        'recall': recall_score(y_true, y_pred, zero_division=0),
        'f1': f1_score(y_true, y_pred, zero_division=0),
        'roc_auc': roc_auc_score(y_true, y_proba)
    }

    print(f"==== Avaliação para {dataset_name} ====")
    for name, value in metrics.items():
        print(f"{name.capitalize()}: {value:.4f}")
    print("====================================")

# Avaliação no treino
evaluate_model(y_train, y_train_pred, y_train_proba, "Treino")

# Avaliação no teste
evaluate_model(y_test, y_test_pred, y_test_proba, "Teste")

# Matriz de Confusão para o conjunto de Teste
cm = confusion_matrix(y_test, y_test_pred)
ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["No Churn", "Churn"]).plot(cmap='Blues')
plt.title("Matriz de Confusão - Teste")
plt.show()